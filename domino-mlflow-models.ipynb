{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a52c0e75",
   "metadata": {},
   "source": [
    "Import common libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432d6cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb78b55",
   "metadata": {},
   "source": [
    "Models with column based inputs work as is (checkout example below - sklearn). Look at the following examples for models with tensor based inputs work when logged as pyfunc (checkout examples below - xgboost, pytorch, tensorflow and simple python functions). \n",
    "\n",
    "Use the test data (example, X_test for xgboost) or the first element of the test data for sending a request to these models. Once you register them and create a model API in Domino, if you are using the tester on the UI, make sure they are properly formatted and the request is of the form : {\"data\": your test data}\n",
    "\n",
    "Logging models using the following templates works with our model APIs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59361746",
   "metadata": {},
   "source": [
    "XGBOOST (array input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cf194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[\"data\"], data[\"target\"], test_size=0.2\n",
    ")\n",
    "\n",
    "xgb_classifier = XGBClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=3,\n",
    "    learning_rate=1,\n",
    "    objective=\"binary:logistic\",\n",
    "    random_state=123,\n",
    ")\n",
    "\n",
    "# train model\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "class SomeModel(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "    # Define a function that returns prediction\n",
    "    def predict(self,context,x):\n",
    "        return self.model.predict(x)\n",
    "\n",
    "model = SomeModel(xgb_classifier)\n",
    "\n",
    "# Create the Pyfunc and log it to MLflow\n",
    "with mlflow.start_run() as run:\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        registered_model_name=\"pyfunc-xgboost-model\", \n",
    "        python_model=model,\n",
    "        artifact_path=\"test-model\"\n",
    "    )\n",
    "print(model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247b83bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf34fd7",
   "metadata": {},
   "source": [
    "SKLEARN (column based inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad66b343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# loading the California housing dataset\n",
    "cali_housing = fetch_california_housing(as_frame=True)\n",
    "\n",
    "# split the dataset into train and test partitions\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cali_housing.data, cali_housing.target, test_size=0.2, random_state=123\n",
    ")\n",
    "\n",
    "# train the model\n",
    "lin_reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Infer model signature\n",
    "predictions = lin_reg.predict(X_train)\n",
    "signature = infer_signature(X_train, predictions)\n",
    "\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.sklearn.log_model(lin_reg, registered_model_name=\"sklearn-model\", artifact_path=\"sklearn-model\", signature=signature)\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c657126",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eca3ac",
   "metadata": {},
   "source": [
    "TENSORFLOW (tensor based inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dac6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10),\n",
    "    ]\n",
    ")\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=\"adam\", loss=loss_fn, metrics=[\"accuracy\"])\n",
    "\n",
    "# train model \n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "class SomeModel(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "    # Define a function that returns prediction\n",
    "    def predict(self,context,x):\n",
    "        x = tf.convert_to_tensor(x)\n",
    "        return self.model.predict(x)\n",
    "\n",
    "model_tf = SomeModel(model)\n",
    "\n",
    "# Create the Pyfunc and log it to MLflow\n",
    "with mlflow.start_run() as run:\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        registered_model_name=\"pyfunc-tensorflow-model\", \n",
    "        python_model=model_tf,\n",
    "        artifact_path=\"test-model\",\n",
    "        pip_requirements=[\"tensorflow\"]\n",
    "    )\n",
    "print(model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6f272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92beb079",
   "metadata": {},
   "source": [
    "PYTORCH (tensor based inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c29714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Linear(6, 1)\n",
    "loss_function = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-4)\n",
    "\n",
    "X = torch.randn(6)\n",
    "y = torch.randn(1)\n",
    "\n",
    "# train model \n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(X)\n",
    "\n",
    "    loss = loss_function(outputs, y)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "class SomeModel(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "    # Define a function that returns prediction\n",
    "    def predict(self,context,x):\n",
    "        x = torch.FloatTensor(x)\n",
    "        return self.model(x).detach().numpy()\n",
    "\n",
    "model = SomeModel(net)\n",
    "\n",
    "# Create the Pyfunc and log it to MLflow\n",
    "with mlflow.start_run() as run:\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        registered_model_name=\"pyfunc-torch-model-4\", # important,\n",
    "        python_model=model,\n",
    "        artifact_path=\"test-model-4\",\n",
    "        pip_requirements=[\"torch\"]\n",
    "    )\n",
    "print(model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc9d039",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7469e3d",
   "metadata": {},
   "source": [
    "CUSTOM PYTHON FUNCTION (tensor based inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b04dc96",
   "metadata": {},
   "source": [
    "Simple python function with artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa17aa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class SomeModel(mlflow.pyfunc.PythonModel):\n",
    "    # Define a function that takes in a NumPy array and returns its sum\n",
    "    def predict(self,context,arr):\n",
    "        return np.sum(arr)\n",
    "\n",
    "# Define a function that generates an artifact in memory\n",
    "def generate_artifact():\n",
    "    data = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\n",
    "    return data.to_csv(\"data.csv\", index=False)\n",
    "\n",
    "generate_artifact()\n",
    "model = SomeModel()\n",
    "\n",
    "# Create the Pyfunc and log it to MLflow\n",
    "with mlflow.start_run() as run:\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        registered_model_name=\"test\", \n",
    "        python_model=model,\n",
    "        artifact_path=\"test-model\",\n",
    "        artifacts={\"model_file\": \"data.csv\"}\n",
    "    )\n",
    "print(model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bbb096",
   "metadata": {},
   "source": [
    "Simple python function without artifact "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867b9b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SomeModel(mlflow.pyfunc.PythonModel):\n",
    "    # Define a function that takes in a NumPy array and returns its sum\n",
    "    def predict(self,context,arr):\n",
    "        return np.sum(arr)\n",
    "\n",
    "# # Define a function that generates an artifact in memory\n",
    "# def generate_artifact():\n",
    "#     data = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\n",
    "#     return data.to_csv(\"data.csv\", index=False)\n",
    "\n",
    "# generate_artifact()\n",
    "model = SomeModel()\n",
    "\n",
    "# Create the Pyfunc and log it to MLflow\n",
    "with mlflow.start_run() as run:\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        registered_model_name=\"test-wo-artifact\",\n",
    "        python_model=model,\n",
    "        artifact_path=\"test-model-1\"\n",
    "        #artifacts={\"model_file\": \"data.csv\"}\n",
    "    )\n",
    "print(model_info)"
   ]
  }
 ],
 "metadata": {
  "dca-init": true,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
